import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse
import pytz
import google.generativeai as genai

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Stock News Hub", layout="wide")
st.title("ğŸš€ AI ê¸°ë°˜ ì™¸ì‹  ì‹¤ì‹œê°„ í—ˆë¸Œ")

# 1ë¶„ë§ˆë‹¤ ìë™ ìƒˆë¡œê³ ì¹¨
st_autorefresh(interval=60000, key="newscheck")

# 1. Gemini ì„¤ì • (Secrets í™•ì¸)
if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        st.error(f"Gemini ì—°ê²° ì‹¤íŒ¨: {e}")
else:
    st.warning("âš ï¸ Streamlit Secretsì— GEMINI_API_KEYë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”. (ë²ˆì—­ ê¸°ëŠ¥ ë¹„í™œì„±í™”)")

# ì¹´í…Œê³ ë¦¬ ì„¤ì •
CATEGORIES = {
    "AI": "AI OR Artificial Intelligence",
    "ë°˜ë„ì²´": "Semiconductor OR Chips",
    "ì—”ë¹„ë””ì•„": "NVIDIA OR NVDA",
    "í…ŒìŠ¬ë¼": "Tesla OR TSLA",
    "ì¼ë¡  ë¨¸ìŠ¤í¬": '"Elon Musk"'
}

def get_category_news(category_name, query):
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    news_data = []
    kst = pytz.timezone('Asia/Seoul')
    
    if hasattr(feed, 'entries'):
        for entry in feed.entries[:8]:
            try:
                # ì‹œê°„ íŒŒì‹± ì—ëŸ¬ ë°©ì§€ìš©
                dt_utc = pd.to_datetime(entry.published, utc=True)
                dt_kst = dt_utc.astimezone(kst)
                
                news_data.append({
                    "ì¹´í…Œê³ ë¦¬": category_name,
                    "í•œêµ­ì‹œê°„": dt_kst.strftime('%m/%d %H:%M'),
                    "ì œëª©": entry.title,
                    "ë§í¬": entry.link,
                    "ì¶œì²˜": entry.source.title if hasattr(entry, 'source') else "Google News",
                    "ìš”ì•½": entry.summary if hasattr(entry, 'summary') else "",
                    "dt": dt_kst
                })
            except:
                continue # ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨í•œ ê¸°ì‚¬ëŠ” ê±´ë„ˆëœ€
    return news_data

# ë‰´ìŠ¤ ìˆ˜ì§‘ë¶€
all_news = []
for cat_name, query in CATEGORIES.items():
    res = get_category_news(cat_name, query)
    if res:
        all_news.extend(res)

# ì¶œë ¥ë¶€
if all_news:
    df = pd.DataFrame(all_news).drop_duplicates(subset=['ì œëª©']).sort_values(by="dt", ascending=False)
    st.subheader(f"ğŸ“ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now(pytz.timezone('Asia/Seoul')).strftime('%H:%M:%S')} (KST)")

    for i, row in df.iterrows():
        with st.container():
            col1, col2, col3 = st.columns([4, 1, 1])
            with col1:
                st.markdown(f"**<{row['ì¹´í…Œê³ ë¦¬']}>** \n[{row['ì¶œì²˜']}] {row['ì œëª©']}")
                st.caption(f"ğŸ•’ {row['í•œêµ­ì‹œê°„']}")
            with col2:
                st.link_button("ê¸°ì‚¬ ì—´ê¸°", row['ë§í¬'])
            with col3:
                if "GEMINI_API_KEY" in st.secrets:
                    if st.button("Gemini ë²ˆì—­", key=f"btn_{i}"):
                        with st.spinner('ë²ˆì—­ ì¤‘...'):
                            prompt = f"ë²ˆì—­í•´ì¤˜: {row['ì œëª©']}"
                            response = model.generate_content(prompt)
                            st.info(f"ğŸ¤– **ë²ˆì—­:** {response.text}")
            st.divider()
else:
    st.info("í˜„ì¬ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 1ë¶„ë§Œ ê¸°ë‹¤ë ¤ë³´ì„¸ìš”.")
