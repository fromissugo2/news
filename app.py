import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse
import pytz

# ==============================
# 1. í˜ì´ì§€ ì„¤ì •
# ==============================
st.set_page_config(page_title="Global Tech News Hub", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ í—ˆë¸Œ")

st_autorefresh(interval=60000, key="news_refresh")

# ==============================
# 2. ì¹´í…Œê³ ë¦¬ ì •ì˜
# ==============================
CATEGORIES = {
    "AI/NVIDIA": "NVIDIA OR NVDA OR 'Artificial Intelligence' OR Blackwell",
    "ë°˜ë„ì²´": "Semiconductor OR Chips OR TSMC OR ASML OR AVGO",
    "í…ŒìŠ¬ë¼/ë¨¸ìŠ¤í¬": "Tesla OR TSLA OR 'Elon Musk' OR Optimus",
    "ë¹…í…Œí¬": "Apple OR Microsoft OR Google OR Meta",
    "ì „ë ¥ ì¸í”„ë¼": "Data Center Energy OR Vertiv OR VRT OR NextEra",
    "ë¡œë³´í‹±ìŠ¤": "Humanoid Robot OR Figure AI OR Boston Dynamics"
}

# ==============================
# 3. ì‹¤ì œ ì›ë¬¸ ë§í¬ ì¶”ì¶œ í•¨ìˆ˜
# ==============================
def extract_real_link(entry):
    try:
        # ê¸°ë³¸ ë§í¬
        link = entry.link

        # Google News ë¦¬ë‹¤ì´ë ‰íŠ¸ì¼ ê²½ìš° ì‹¤ì œ ë§í¬ ì¶”ì¶œ ì‹œë„
        if "news.google.com" in link:
            for l in entry.links:
                if l.get("type") == "text/html":
                    return l.get("href")

        return link
    except:
        return entry.link


# ==============================
# 4. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
# ==============================
def get_news_feed(category_name, query):
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)

    news_list = []
    kst = pytz.timezone('Asia/Seoul')

    if hasattr(feed, 'entries'):
        for entry in feed.entries[:8]:
            try:
                dt_utc = pd.to_datetime(entry.published, utc=True)

                full_title = entry.title
                title_part = full_title.rsplit(' - ', 1)[0] if ' - ' in full_title else full_title
                source_part = entry.source.title if hasattr(entry, 'source') else "News Source"

                real_link = extract_real_link(entry)

                news_list.append({
                    "category": category_name,
                    "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                    "title": title_part,
                    "real_link": real_link,
                    "source": source_part,
                    "dt": dt_utc
                })
            except:
                continue

    return news_list


# ==============================
# 5. ë‰´ìŠ¤ ì‹¤í–‰ ë° ì¶œë ¥
# ==============================
all_news = []

for cat_name, query in CATEGORIES.items():
    all_news.extend(get_news_feed(cat_name, query))

if all_news:
    df = (
        pd.DataFrame(all_news)
        .drop_duplicates(subset=['title'])
        .sort_values(by="dt", ascending=False)
    )

    st.info("âœ… GeminiëŠ” ë°˜ë“œì‹œ í•´ë‹¹ ê¸°ì‚¬ ë§í¬ë§Œ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    for i, row in df.iterrows():
        with st.container():
            col1, col2 = st.columns([3, 1.3])

            with col1:
                st.markdown(f"### <{row['category']}> {row['title']}")
                st.caption(f"ğŸ•’ {row['time']} | ì¶œì²˜: {row['source']}")
                st.link_button("ğŸ“„ ì›ë¬¸ ê¸°ì‚¬ ì§ì ‘ ë³´ê¸°", row['real_link'])

            with col2:

                prompt_text = (
                    f"ë‹¤ìŒ ê¸°ì‚¬ ë§í¬ì˜ ë‚´ìš©ì„ ì§ì ‘ í™•ì¸í•˜ê³  ë¶„ì„í•´ì¤˜:\n\n"
                    f"{row['real_link']}\n\n"
                    f"âš  ë°˜ë“œì‹œ ìœ„ ë§í¬ ê¸°ì‚¬ ë‚´ìš©ë§Œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´.\n"
                    f"ë‹¤ë¥¸ ê¸°ì‚¬ ê²€ìƒ‰ì´ë‚˜ ìœ ì‚¬ ê¸°ì‚¬ ì¶”ì¸¡ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.\n\n"
                    f"ë‹¤ìŒ ìˆœì„œë¡œ ë‹µí•´ì¤˜:\n\n"
                    f"1. **ê¸°ì‚¬ ì „ë¬¸ ë²ˆì—­ ë° ìƒì„¸ ìš”ì•½**\n"
                    f"   - ê¸°ì‚¬ ì „ì²´ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê²Œ ë²ˆì—­\n"
                    f"   - í•µì‹¬ ë‚´ìš©ì„ ë†“ì¹¨ ì—†ì´ ìì„¸í•˜ê²Œ ìš”ì•½\n\n"
                    f"2. **êµ­ì™¸(ê¸€ë¡œë²Œ) ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                    f"   - ì˜í–¥ì„ ë°›ëŠ” í•´ì™¸ ì£¼ìš” ì¢…ëª© ë° ì„¹í„° ë¶„ì„\n\n"
                    f"3. **êµ­ë‚´ ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                    f"   - êµ­ë‚´ ì‹œì¥ ì˜í–¥ ì—¬ë¶€ ë° ê´€ë ¨ ì¢…ëª©/í…Œë§ˆ ë¶„ì„\n\n"
                    f"4. **íˆ¬ìì ê´€ì  ìµœì¢… ê²°ë¡ **\n"
                    f"   - ì‹œì¥ ì‹œê·¸ë„ ë° íˆ¬ì ë§¤ë ¥ë„ í‰ê°€"
                )

                st.text_area(
                    "ëª…ë ¹ì–´ ë³µì‚¬ (Ctrl+C)",
                    value=prompt_text,
                    height=180,
                    key=f"copy_{i}"
                )

                st.link_button(
                    "ğŸ¤– Gemini ì—´ê¸°",
                    "https://gemini.google.com/app",
                    type="primary",
                    use_container_width=True
                )

            st.divider()

else:
    st.warning("í˜„ì¬ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
