import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse
import pytz

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Global Tech News Hub", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ í—ˆë¸Œ (Gemini ì—°ê²°)")

# 1ë¶„ë§ˆë‹¤ ìë™ ìƒˆë¡œê³ ì¹¨ (RSS ì—…ë°ì´íŠ¸ í™•ì¸ìš©)
st_autorefresh(interval=60000, key="news_refresh")

# 2. ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì„¤ì •
CATEGORIES = {
    "AI": "AI OR Artificial Intelligence",
    "ë°˜ë„ì²´": "Semiconductor OR Chips",
    "ì—”ë¹„ë””ì•„": "NVIDIA OR NVDA",
    "í…ŒìŠ¬ë¼": "Tesla OR TSLA",
    "ì¼ë¡  ë¨¸ìŠ¤í¬": '"Elon Musk"'
}

# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_news_feed(category_name, query):
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    news_list = []
    kst = pytz.timezone('Asia/Seoul')
    
    if hasattr(feed, 'entries'):
        for entry in feed.entries[:10]: # APIë¥¼ ì•ˆ ì“°ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ 10ê°œì”© ìˆ˜ì§‘
            try:
                dt_utc = pd.to_datetime(entry.published, utc=True)
                news_list.append({
                    "category": category_name,
                    "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                    "title": entry.title,
                    "link": entry.link,
                    "source": entry.source.title if hasattr(entry, 'source') else "News",
                    "dt": dt_utc
                })
            except: continue
    return news_list

# 4. ë©”ì¸ ì‹¤í–‰
all_news = []
for cat_name, query in CATEGORIES.items():
    all_news.extend(get_news_feed(cat_name, query))

if all_news:
    df = pd.DataFrame(all_news).drop_duplicates(subset=['title']).sort_values(by="dt", ascending=False)
    
    st.subheader(f"ğŸ“ ì—…ë°ì´íŠ¸: {datetime.now(pytz.timezone('Asia/Seoul')).strftime('%H:%M:%S')} (KST)")
    st.info("ğŸ’¡ 'AI ë²ˆì—­/ìš”ì•½' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ Geminië¡œ ì—°ê²°ë©ë‹ˆë‹¤. ì›ë¬¸ ë§í¬ê°€ ìë™ í¬í•¨ë©ë‹ˆë‹¤.")
    st.divider()

    for i, row in df.iterrows():
        with st.container():
            col1, col2, col3 = st.columns([4, 1, 1.5])
            
            with col1:
                st.markdown(f"**<{row['category']}> {row['title']}**")
                st.caption(f"ğŸ•’ {row['time']} | ì¶œì²˜: {row['source']}")
            
            with col2:
                st.link_button("ì›ë³¸ ê¸°ì‚¬ â†—ï¸", row['link'])
            
            with col3:
                # [í•µì‹¬] Gemini ì—°ê²° ë§í¬ ìƒì„±
                # ê¸°ì‚¬ ë§í¬ì™€ í•¨ê»˜ ë²ˆì—­/ìš”ì•½ ìš”ì²­ ë©”ì‹œì§€ë¥¼ URL ì¸ì½”ë”©í•˜ì—¬ ì „ë‹¬
                prompt = f"ì´ ê¸°ì‚¬ ë§í¬ ì½ê³  í•œêµ­ì–´ë¡œ ì „ë¬¸ ë²ˆì—­í•˜ê³  3ì¤„ ìš”ì•½í•´ì¤˜: {row['link']}"
                encoded_prompt = urllib.parse.quote(prompt)
                gemini_url = f"https://gemini.google.com/app?prompt={encoded_prompt}"
                
                st.link_button("ğŸ¤– Gemini ë²ˆì—­/ìš”ì•½", gemini_url, type="primary")
            
            st.divider()
else:
    st.info("í˜„ì¬ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
