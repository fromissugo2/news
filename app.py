import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime, timedelta
import urllib.parse
import pytz
import hashlib
import requests

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Global Tech News Hub", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ í—ˆë¸Œ")

# 60ì´ˆë§ˆë‹¤ í™”ë©´ ìë™ ê°±ì‹ 
st_autorefresh(interval=60000, key="news_refresh")

# 2. ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = {
    "AI/NVIDIA": "NVIDIA NVDA Artificial Intelligence Blackwell",
    "ë°˜ë„ì²´": "Semiconductor Chips TSMC ASML AVGO",
    "í…ŒìŠ¬ë¼/ë¨¸ìŠ¤í¬": "Tesla TSLA Elon Musk Optimus",
    "ë¹…í…Œí¬": "Apple Microsoft Google Meta",
    "ì „ë ¥ ì¸í”„ë¼": "Data Center Energy Vertiv VRT NextEra",
    "ë¡œë³´í‹±ìŠ¤": "Humanoid Robot Figure AI Boston Dynamics",
    "ê°€ìƒí™”í/ë¨¸ìŠ¤í¬/AI": "Bitcoin Ethereum Crypto Elon Musk AI"
}

# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (Finnhub + í‚¤ì›Œë“œ í•„í„°ë§)
@st.cache_data(ttl=60)
def get_news_feed(category_name, keywords):
    news_list = []
    kst = pytz.timezone('Asia/Seoul')
    now_utc = datetime.now(pytz.utc)

    api_key = st.secrets.get("FINNHUB_API_KEY")

    if not api_key:
        st.error("âš ï¸ FINNHUB_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    try:
        # ìµœê·¼ 1ì¼ ë‰´ìŠ¤ í˜¸ì¶œ (Finnhub ë¬´ë£Œ í”Œëœ ì•ˆì •)
        today = datetime.utcnow().date()
        yesterday = today - timedelta(days=1)

        url = "https://finnhub.io/api/v1/news"
        params = {
            "category": "general",
            "from": yesterday.strftime("%Y-%m-%d"),
            "to": today.strftime("%Y-%m-%d"),
            "token": api_key
        }

        response = requests.get(url, params=params, timeout=10)

        if response.status_code != 200:
            st.error(f"Finnhub API ì˜¤ë¥˜ (ì½”ë“œ: {response.status_code})")
            return []

        data = response.json()

        keyword_list = keywords.lower().split()

        for entry in data:
            try:
                dt_utc = datetime.fromtimestamp(entry['datetime'], pytz.utc)

                # 1ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ í—ˆìš©
                if (now_utc - dt_utc).total_seconds() > 3600:
                    continue

                title = entry['headline']
                summary = entry.get('summary', '')
                combined_text = f"{title} {summary}".lower()

                # í‚¤ì›Œë“œ í•„í„°ë§
                if not any(word.lower() in combined_text for word in keyword_list):
                    continue

                item_id = hashlib.md5(title.encode()).hexdigest()[:12]

                news_list.append({
                    "id": item_id,
                    "category": category_name,
                    "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                    "title": title,
                    "google_link": entry['url'],
                    "source": entry.get('source', 'Finnhub'),
                    "dt": dt_utc
                })

            except:
                continue

    except Exception as e:
        st.error(f"Finnhub API ì—ëŸ¬: {e}")

    return sorted(news_list, key=lambda x: x['dt'], reverse=True)


# 4. ìƒë‹¨ ê³µí†µ ì•ˆë‚´
st.info("ğŸ’¡ **ì´ìš© ê°€ì´ë“œ**: íƒ­ì„ í´ë¦­í•´ ì‹¤ì‹œê°„ ì†ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”. 1ì‹œê°„ ì´ë‚´ì˜ ìµœì‹  ê¸°ì‚¬ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

# 5. ìƒë‹¨ íƒ­ êµ¬ì„±
tabs = st.tabs(list(CATEGORIES.keys()))

# 6. ê° íƒ­ë³„ ë‰´ìŠ¤ ì¶œë ¥
for tab_idx, (tab, (cat_name, keywords)) in enumerate(zip(tabs, CATEGORIES.items())):
    with tab:
        news_data = get_news_feed(cat_name, keywords)
        now_kst = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%H:%M:%S')

        if news_data:
            df = pd.DataFrame(news_data)
            st.caption(f"ğŸ”¥ í˜„ì¬ **{len(df)}ê°œ**ì˜ ìµœì‹  ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ ê°±ì‹ : {now_kst})")

            for i, (_, row) in enumerate(df.iterrows()):
                widget_key = f"copy_{tab_idx}_{i}_{row['id']}"

                with st.container():
                    col1, col2 = st.columns([3, 1.2])

                    with col1:
                        st.markdown(f"### {row['title']}")
                        st.caption(f"ğŸ•’ {row['time']} | ì¶œì²˜: {row['source']}")
                        st.link_button(f"ğŸ“„ {row['source']} ì›ë¬¸ ê¸°ì‚¬ ë³´ê¸°", row['google_link'])

                    with col2:
                        prompt_text = (
                            f"ì¶œì²˜ê°€ '{row['source']}'ì¸ '{row['title']}' ê¸°ì‚¬ë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ ìˆœì„œë¡œ ë‹µí•´ì¤˜:\n\n"
                            f"1. **ê¸°ì‚¬ ì „ë¬¸ ë²ˆì—­ ë° ìƒì„¸ ìš”ì•½**\n"
                            f"2. **êµ­ì™¸(ê¸€ë¡œë²Œ) ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„± ë¶„ì„**\n"
                            f"3. **êµ­ë‚´ ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„± ë¶„ì„**\n"
                            f"4. **íˆ¬ìì ê´€ì  ìµœì¢… ê²°ë¡ **"
                        )

                        st.text_area("ëª…ë ¹ì–´ ë³µì‚¬ (Ctrl+C)", value=prompt_text, height=150, key=widget_key)
                        st.link_button("ğŸ¤– Gemini ì—´ê¸°", "https://gemini.google.com/app", type="primary", use_container_width=True)

                    st.divider()

        else:
            st.warning(f"í˜„ì¬ '{cat_name}' ì¹´í…Œê³ ë¦¬ì— ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ìë™ í•„í„°ë§ ì¤‘)")
