import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse
import pytz
import hashlib

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Global Tech News Hub", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ í—ˆë¸Œ")

# 60ì´ˆë§ˆë‹¤ í™”ë©´ ìë™ ê°±ì‹  (ëª…ë ¹ì–´ ë¶ˆì¼ì¹˜ ë°©ì§€ ë¡œì§ í¬í•¨)
st_autorefresh(interval=60000, key="news_refresh")

# 2. ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = {
    "AI/NVIDIA": "NVIDIA OR NVDA OR 'Artificial Intelligence' OR Blackwell",
    "ë°˜ë„ì²´": "Semiconductor OR Chips OR TSMC OR ASML OR AVGO",
    "í…ŒìŠ¬ë¼/ë¨¸ìŠ¤í¬": "Tesla OR TSLA OR 'Elon Musk' OR Optimus",
    "ë¹…í…Œí¬": "Apple OR Microsoft OR Google OR Meta",
    "ì „ë ¥ ì¸í”„ë¼": "Data Center Energy OR Vertiv OR VRT OR NextEra",
    "ë¡œë³´í‹±ìŠ¤": "Humanoid Robot OR Figure AI OR Boston Dynamics"
}

# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_news_feed(category_name, query):
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    news_list = []
    kst = pytz.timezone('Asia/Seoul')
    
    if hasattr(feed, 'entries'):
        for entry in feed.entries[:10]: # íƒ­ë³„ë¡œ ë³´ì—¬ì£¼ë¯€ë¡œ 10ê°œê¹Œì§€ í™•ëŒ€
            try:
                dt_utc = pd.to_datetime(entry.published, utc=True)
                full_title = entry.title
                title_part = full_title.rsplit(' - ', 1)[0] if ' - ' in full_title else full_title
                source_part = entry.source.title if hasattr(entry, 'source') else "News Source"
                
                # ìœ„ì ¯ ê°±ì‹ ì„ ìœ„í•œ ê³ ìœ  í•´ì‹œ ID ìƒì„±
                item_id = hashlib.md5(title_part.encode()).hexdigest()[:12]
                
                news_list.append({
                    "id": item_id,
                    "category": category_name,
                    "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                    "title": title_part,
                    "google_link": entry.link,
                    "source": source_part,
                    "dt": dt_utc
                })
            except: continue
    return news_list

# 4. ìƒë‹¨ íƒ­ êµ¬ì„±
tabs = st.tabs(list(CATEGORIES.keys()))

# 5. ê° íƒ­ë³„ ë‰´ìŠ¤ ì¶œë ¥ ë£¨í”„
for tab, (cat_name, query) in zip(tabs, CATEGORIES.items()):
    with tab:
        news_data = get_news_feed(cat_name, query)
        
        if news_data:
            df = pd.DataFrame(news_data).sort_values(by="dt", ascending=False)
            st.info(f"âœ… '{cat_name}' ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤. (1ë¶„ë§ˆë‹¤ ìë™ ì—…ë°ì´íŠ¸)")
            
            for _, row in df.iterrows():
                # ë°ì´í„°ê°€ ë°”ë€Œë©´ ìœ„ì ¯ë„ ìƒˆë¡œ ê·¸ë ¤ì§€ë„ë¡ ê³ ìœ  í‚¤ ì„¤ì •
                widget_key = f"copy_{row['id']}_{cat_name}"
                
                with st.container():
                    col1, col2 = st.columns([3, 1.2])
                    
                    with col1:
                        st.markdown(f"### {row['title']}")
                        st.caption(f"ğŸ•’ {row['time']} | ì¶œì²˜: {row['source']}")
                        st.link_button(f"ğŸ“„ {row['source']} ì›ë¬¸ ê¸°ì‚¬ ë³´ê¸°", row['google_link'])
                    
                    with col2:
                        # ìš”ì²­í•˜ì‹  ìƒì„¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                        prompt_text = (
                            f"ì¶œì²˜ê°€ '{row['source']}'ì¸ '{row['title']}' ê¸°ì‚¬ë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ ìˆœì„œë¡œ ë‹µí•´ì¤˜:\n\n"
                            f"1. **ê¸°ì‚¬ ì „ë¬¸ ë²ˆì—­ ë° ìƒì„¸ ìš”ì•½**\n"
                            f"   - ê¸°ì‚¬ ì „ì²´ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê²Œ ë²ˆì—­\n"
                            f"   - í•µì‹¬ ë‚´ìš©ì„ ë†“ì¹¨ ì—†ì´ ìì„¸í•˜ê²Œ ìš”ì•½\n\n"
                            f"2. **êµ­ì™¸(ê¸€ë¡œë²Œ) ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                            f"   - í•´ë‹¹ ì†Œì‹ìœ¼ë¡œ ì˜í–¥ì„ ë°›ëŠ” ë¯¸êµ­ ë“± í•´ì™¸ ì£¼ìš” ì¢…ëª©ê³¼ ì„¹í„° ë¶„ì„\n\n"
                            f"3. **êµ­ë‚´ ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                            f"   - êµ­ë‚´ ì‹œì¥ì—ì„œë„ ì˜í–¥ì´ ìˆì„ì§€ ì—¬ë¶€ì™€ êµ¬ì²´ì ì¸ ì´ìœ \n"
                            f"   - ì—°ê´€ëœ êµ­ë‚´ ì£¼ì‹ ì¢…ëª©(ìˆ˜í˜œì£¼/í”¼í•´ì£¼)ê³¼ ê´€ë ¨ í…Œë§ˆ(ì˜ˆ: HBM, ììœ¨ì£¼í–‰ ë“±)\n\n"
                            f"4. **íˆ¬ìì ê´€ì ì˜ ìµœì¢… ê²°ë¡ **\n"
                            f"   - ì´ ê¸°ì‚¬ê°€ ì‹œì¥ì— ì£¼ëŠ” ì‹œê·¸ë„ ìš”ì•½ ë° íˆ¬ì ë§¤ë ¥ë„ ë¶„ì„"
                        )
                        
                        st.text_area("ëª…ë ¹ì–´ ë³µì‚¬ (Ctrl+C)", value=prompt_text, height=150, key=widget_key)
                        st.link_button("ğŸ¤– Gemini ì—´ê¸°", "https://gemini.google.com/app", type="primary", use_container_width=True)
                    
                    st.divider()
        else:
            st.warning(f"í˜„ì¬ '{cat_name}' ì¹´í…Œê³ ë¦¬ì— ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
