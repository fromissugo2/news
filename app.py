import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
import urllib.parse
import pytz
import hashlib

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Tech News Dashboard", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ í—ˆë¸Œ")

# 60ì´ˆë§ˆë‹¤ ìë™ ê°±ì‹ 
st_autorefresh(interval=60000, key="news_refresh")

# 2. ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = {
    "AI/NVIDIA": "NVIDIA OR NVDA OR 'Artificial Intelligence' OR Blackwell",
    "ë°˜ë„ì²´": "Semiconductor OR Chips OR TSMC OR ASML OR AVGO",
    "í…ŒìŠ¬ë¼/ë¨¸ìŠ¤í¬": "Tesla OR TSLA OR 'Elon Musk' OR Optimus",
    "ë¹…í…Œí¬": "Apple OR Microsoft OR Google OR Meta",
    "ì „ë ¥ ì¸í”„ë¼": "Data Center Energy OR Vertiv OR VRT OR NextEra",
    "ë¡œë³´í‹±ìŠ¤": "Humanoid Robot OR Figure AI OR Boston Dynamics"
}

# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_news_feed(category_name, query):
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    news_list = []
    kst = pytz.timezone('Asia/Seoul')
    
    if hasattr(feed, 'entries'):
        for entry in feed.entries[:10]: # íƒ­ë³„ë¡œ ë³´ì—¬ì£¼ë¯€ë¡œ ê°œìˆ˜ë¥¼ ì¡°ê¸ˆ ëŠ˜ë ¤ë„ ê°€ë…ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤.
            try:
                dt_utc = pd.to_datetime(entry.published, utc=True)
                full_title = entry.title
                title_part = full_title.rsplit(' - ', 1)[0] if ' - ' in full_title else full_title
                source_part = entry.source.title if hasattr(entry, 'source') else "News Source"
                item_id = hashlib.md5(title_part.encode()).hexdigest()[:10]
                
                news_list.append({
                    "id": item_id,
                    "category": category_name,
                    "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                    "title": title_part,
                    "google_link": entry.link,
                    "source": source_part,
                    "dt": dt_utc
                })
            except: continue
    return news_list

# 4. íƒ­ ìƒì„± (ì¹´í…Œê³ ë¦¬ ì´ë¦„ìœ¼ë¡œ íƒ­ì„ ë§Œë“­ë‹ˆë‹¤)
tab_titles = list(CATEGORIES.keys())
tabs = st.tabs(tab_titles)

# 5. ê° íƒ­ë³„ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì¶œë ¥
for tab, (cat_name, query) in zip(tabs, CATEGORIES.items()):
    with tab:
        news_data = get_news_feed(cat_name, query)
        
        if news_data:
            # ì‹œê°„ìˆœ ì •ë ¬
            df = pd.DataFrame(news_data).sort_values(by="dt", ascending=False)
            
            st.caption(f"ğŸ“ í˜„ì¬ {len(df)}ê°œì˜ ìµœì‹  ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. (1ë¶„ ê°„ê²© ìë™ ê°±ì‹ )")
            
            for _, row in df.iterrows():
                # ê³ ìœ  í‚¤ ìƒì„±
                widget_key = f"area_{row['id']}_{cat_name}"
                
                with st.container():
                    col1, col2 = st.columns([3, 1.2])
                    
                    with col1:
                        st.markdown(f"### {row['title']}")
                        st.caption(f"ğŸ•’ {row['time']} | ì¶œì²˜: {row['source']}")
                        st.link_button(f"ğŸ“„ {row['source']} ì›ë¬¸ ë³´ê¸°", row['google_link'])
                    
                    with col2:
                        prompt_text = (
                            f"ì¶œì²˜ê°€ '{row['source']}'ì¸ '{row['title']}' ê¸°ì‚¬ë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ ìˆœì„œë¡œ ë‹µí•´ì¤˜:\n\n"
                            f"1. **ê¸°ì‚¬ ì „ë¬¸ ë²ˆì—­ ë° ìƒì„¸ ìš”ì•½**\n"
                            f"2. **êµ­ì™¸(ê¸€ë¡œë²Œ) ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                            f"3. **êµ­ë‚´ ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                            f"4. **íˆ¬ìì ê´€ì ì˜ ìµœì¢… ê²°ë¡ **"
                        )
                        
                        st.text_area("ëª…ë ¹ì–´ ë³µì‚¬", value=prompt_text, height=100, key=widget_key)
                        st.link_button("ğŸ¤– Gemini ì‹¤í–‰", "https://gemini.google.com/app", type="primary", use_container_width=True)
                    st.divider()
        else:
            st.info(f"í˜„ì¬ '{cat_name}' ì¹´í…Œê³ ë¦¬ì— ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
