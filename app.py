import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse
import pytz
import google.generativeai as genai
import re
from newspaper import Article

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Global Tech News Hub", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ & AI ì œëª© ë²ˆì—­")

st_autorefresh(interval=60000, key="news_refresh")

# 2. Gemini ì„¤ì •
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel('gemini-flash-latest')
else:
    st.warning("âš ï¸ Secretsì— API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")

# 3. ì œëª© ë²ˆì—­ ì „ìš© í•¨ìˆ˜ (ìºì‹œ ì ìš©í•˜ì—¬ ì†ë„ í–¥ìƒ)
@st.cache_data(ttl=3600)
def translate_title(title_text):
    try:
        prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ì„ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì¤˜. ê²°ê³¼ë§Œ ë”± í•œ ì¤„ë¡œ ë§í•´ì¤˜: {title_text}"
        response = model.generate_content(prompt)
        return response.text.strip()
    except:
        return title_text

# 4. ë³¸ë¬¸ ì¶”ì¶œ ë° ë¶„ì„ í•¨ìˆ˜
@st.cache_data(ttl=3600)
def get_full_article_translation(url, fallback_summary):
    try:
        article = Article(url, language='en')
        article.download()
        article.parse()
        full_text = article.text
        
        if full_text and len(full_text) > 200:
            prompt = (
                f"ë‹¹ì‹ ì€ í…Œí¬/ê²½ì œ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ê¸°ì‚¬ ì „ë¬¸ì„ í•œêµ­ì–´ë¡œ ì½ê¸° ì‰½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\n"
                f"ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ '### ğŸ’¡ 3ì¤„ í•µì‹¬ ìš”ì•½' ì„¹ì…˜ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n\n"
                f"ê¸°ì‚¬ ë³¸ë¬¸:\n{full_text[:4000]}"
            )
        else:
            prompt = (
                f"ë³¸ë¬¸ í¬ë¡¤ë§ì´ ì œí•œë˜ì–´ ìš”ì•½ë³¸ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ í’€ì–´ì„œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n\nìš”ì•½ ì •ë³´:\n{fallback_summary}"
            )
        
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âš ï¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# 5. ìƒˆ ì°½(Dialog) ì •ì˜
@st.dialog("ğŸ“‹ AI ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸", width="large")
def show_full_translation(translated_title, original_title, url, summary):
    st.markdown(f"### {translated_title}")
    st.caption(f"Original: {original_title}")
    st.caption(f"ğŸ”— ì›ë¬¸: {url}")
    st.divider()
    
    with st.container(height=600): 
        with st.spinner('AIê°€ ê¸°ì‚¬ ë‚´ìš©ì„ ì‹¬ì¸µ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            result = get_full_article_translation(url, f"ì œëª©: {original_title}\nìš”ì•½: {summary}")
            st.markdown(result)
    
    if st.button("ë‹«ê¸°"):
        st.rerun()

# 6. ë‰´ìŠ¤ ìˆ˜ì§‘ ë¡œì§
CATEGORIES = {
    "AI": "AI OR Artificial Intelligence",
    "ë°˜ë„ì²´": "Semiconductor OR Chips",
    "ì—”ë¹„ë””ì•„": "NVIDIA OR NVDA",
    "í…ŒìŠ¬ë¼": "Tesla OR TSLA",
    "ì¼ë¡  ë¨¸ìŠ¤í¬": '"Elon Musk"'
}

def get_news_feed(category_name, query):
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(url)
    news_list = []
    kst = pytz.timezone('Asia/Seoul')
    
    if hasattr(feed, 'entries'):
        for entry in feed.entries[:6]: # ì†ë„ë¥¼ ìœ„í•´ ì¹´í…Œê³ ë¦¬ë‹¹ 6ê°œë¡œ ì¡°ì •
            try:
                dt_utc = pd.to_datetime(entry.published, utc=True)
                news_list.append({
                    "category": category_name,
                    "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                    "title": entry.title,
                    "link": entry.link,
                    "summary": entry.summary,
                    "source": entry.source.title if hasattr(entry, 'source') else "News",
                    "dt": dt_utc
                })
            except: continue
    return news_list

# 7. ë©”ì¸ ì¶œë ¥ í™”ë©´
all_news = []
for cat_name, query in CATEGORIES.items():
    all_news.extend(get_news_feed(cat_name, query))

if all_news:
    df = pd.DataFrame(all_news).drop_duplicates(subset=['title']).sort_values(by="dt", ascending=False)
    
    st.subheader(f"ğŸ“ ì—…ë°ì´íŠ¸: {datetime.now(pytz.timezone('Asia/Seoul')).strftime('%H:%M:%S')} (KST)")
    st.divider()

    for i, row in df.iterrows():
        # ë©”ì¸ í™”ë©´ ì œëª© ë²ˆì—­
        with st.spinner('ì œëª© ë²ˆì—­ ì¤‘...'):
            korean_title = translate_title(row['title'])
            
        with st.container():
            col1, col2, col3 = st.columns([4, 0.8, 1])
            with col1:
                # ë²ˆì—­ëœ ì œëª©ì„ í¬ê²Œ, ì›ë¬¸ ì œëª©ì„ ì‘ê²Œ í‘œì‹œ
                st.markdown(f"**<{row['category']}> {korean_title}**")
                st.caption(f"[{row['source']}] {row['title']}")
                st.caption(f"ğŸ•’ {row['time']}")
            with col2:
                st.link_button("ì›ë³¸", row['link'])
            with col3:
                if st.button("AI ë¶„ì„", key=f"btn_{i}"):
                    show_full_translation(korean_title, row['title'], row['link'], row['summary'])
            st.divider()
else:
    st.info("í˜„ì¬ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
