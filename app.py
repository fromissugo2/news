import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse
import pytz
import hashlib
import requests

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Global Tech News Hub", layout="wide")
st.title("ğŸ“¡ ì‹¤ì‹œê°„ ì™¸ì‹  í…Œí¬ ë‰´ìŠ¤ í—ˆë¸Œ")

# 60ì´ˆë§ˆë‹¤ í™”ë©´ ìë™ ê°±ì‹ 
st_autorefresh(interval=60000, key="news_refresh")

# 2. ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = {
    "AI/NVIDIA": "NVIDIA OR NVDA OR 'Artificial Intelligence' OR Blackwell",
    "ë°˜ë„ì²´": "Semiconductor OR Chips OR TSMC OR ASML OR AVGO",
    "í…ŒìŠ¬ë¼/ë¨¸ìŠ¤í¬": "Tesla OR TSLA OR 'Elon Musk' OR Optimus",
    "ë¹…í…Œí¬": "Apple OR Microsoft OR Google OR Meta",
    "ì „ë ¥ ì¸í”„ë¼": "Data Center Energy OR Vertiv OR VRT OR NextEra",
    "ë¡œë³´í‹±ìŠ¤": "Humanoid Robot OR Figure AI OR Boston Dynamics",
    "ê°€ìƒí™”í/ë¨¸ìŠ¤í¬/AI": "CRYPTO_PANIC"
}

# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_news_feed(category_name, query):
    news_list = []
    kst = pytz.timezone('Asia/Seoul')
    now_utc = datetime.now(pytz.utc)

    # --- Case 1: CryptoPanic API (ë¬´ë£Œ í”Œëœ ëŒ€ì‘ ë²„ì „) ---
    if query == "CRYPTO_PANIC":
        try:
            api_key = st.secrets.get("CP_API_KEY")

            if api_key:
                cp_url = "https://cryptopanic.com/api/v1/posts/"

                # âœ… ë¬´ë£Œ í”Œëœ ìµœì†Œ íŒŒë¼ë¯¸í„°
                params = {
                    "auth_token": api_key
                }

                response = requests.get(cp_url, params=params, timeout=10)

                if response.status_code == 200:
                    data = response.json()

                    for entry in data.get('results', [])[:30]:
                        try:
                            dt_utc = pd.to_datetime(entry['published_at'], utc=True)

                            # 2ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ í—ˆìš©
                            if (now_utc - dt_utc).total_seconds() > 7200:
                                continue

                            title = entry['title']
                            item_id = hashlib.md5(title.encode()).hexdigest()[:12]

                            news_list.append({
                                "id": item_id,
                                "category": category_name,
                                "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                                "title": title,
                                "google_link": entry['url'],
                                "source": entry.get('domain', 'CryptoPanic'),
                                "dt": dt_utc
                            })
                        except:
                            continue
                else:
                    st.error(f"CryptoPanic API ì‘ë‹µ ì˜¤ë¥˜ (ì½”ë“œ: {response.status_code})")
                    st.caption(f"ìš”ì²­ URL: {response.url}")

            else:
                st.warning("âš ï¸ CryptoPanic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

        except Exception as e:
            st.error(f"CryptoPanic API ì—ëŸ¬: {e}")

    # --- Case 2: Google News RSS ---
    else:
        encoded_query = urllib.parse.quote(f"{query} when:1h")
        url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
        feed = feedparser.parse(url)

        if hasattr(feed, 'entries'):
            for entry in feed.entries[:50]:
                try:
                    dt_utc = pd.to_datetime(entry.published, utc=True)

                    # 1ì‹œê°„ ì´ìƒ ê²½ê³¼ ê¸°ì‚¬ ì œì™¸
                    if (now_utc - dt_utc).total_seconds() > 3600:
                        continue

                    full_title = entry.title
                    title_part = full_title.rsplit(' - ', 1)[0] if ' - ' in full_title else full_title
                    source_part = entry.source.title if hasattr(entry, 'source') else "News Source"
                    item_id = hashlib.md5(title_part.encode()).hexdigest()[:12]

                    news_list.append({
                        "id": item_id,
                        "category": category_name,
                        "time": dt_utc.astimezone(kst).strftime('%m/%d %H:%M'),
                        "title": title_part,
                        "google_link": entry.link,
                        "source": source_part,
                        "dt": dt_utc
                    })
                except:
                    continue

    return sorted(news_list, key=lambda x: x['dt'], reverse=True)

# 4. ìƒë‹¨ ê³µí†µ ì•ˆë‚´
st.info("ğŸ’¡ **ì´ìš© ê°€ì´ë“œ**: íƒ­ì„ í´ë¦­í•´ ì‹¤ì‹œê°„ ì†ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”. 1ì‹œê°„ ì´ë‚´ì˜ ìµœì‹  ê¸°ì‚¬ë§Œ í‘œì‹œë©ë‹ˆë‹¤. (ê°€ìƒí™”í íƒ­ì€ 2ì‹œê°„)")

# 5. ìƒë‹¨ íƒ­ êµ¬ì„±
tabs = st.tabs(list(CATEGORIES.keys()))

# 6. ê° íƒ­ë³„ ë‰´ìŠ¤ ì¶œë ¥
for tab_idx, (tab, (cat_name, query)) in enumerate(zip(tabs, CATEGORIES.items())):
    with tab:
        news_data = get_news_feed(cat_name, query)
        now_kst = datetime.now(pytz.timezone('Asia/Seoul')).strftime('%H:%M:%S')

        if news_data:
            df = pd.DataFrame(news_data)
            st.caption(f"ğŸ”¥ í˜„ì¬ **{len(df)}ê°œ**ì˜ ìµœì‹  ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ ê°±ì‹ : {now_kst})")

            for i, (_, row) in enumerate(df.iterrows()):
                widget_key = f"copy_{tab_idx}_{i}_{row['id']}"

                with st.container():
                    col1, col2 = st.columns([3, 1.2])

                    with col1:
                        st.markdown(f"### {row['title']}")
                        st.caption(f"ğŸ•’ {row['time']} | ì¶œì²˜: {row['source']}")
                        st.link_button(f"ğŸ“„ {row['source']} ì›ë¬¸ ê¸°ì‚¬ ë³´ê¸°", row['google_link'])

                    with col2:
                        prompt_text = (
                            f"ì¶œì²˜ê°€ '{row['source']}'ì¸ '{row['title']}' ê¸°ì‚¬ë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ ìˆœì„œë¡œ ë‹µí•´ì¤˜:\n\n"
                            f"1. **ê¸°ì‚¬ ì „ë¬¸ ë²ˆì—­ ë° ìƒì„¸ ìš”ì•½**\n"
                            f"   - ê¸°ì‚¬ ì „ì²´ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê²Œ ë²ˆì—­\n"
                            f"   - í•µì‹¬ ë‚´ìš©ì„ ë†“ì¹¨ ì—†ì´ ìì„¸í•˜ê²Œ ìš”ì•½\n\n"
                            f"2. **êµ­ì™¸(ê¸€ë¡œë²Œ) ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                            f"   - í•´ë‹¹ ì†Œì‹ìœ¼ë¡œ ì˜í–¥ì„ ë°›ëŠ” ë¯¸êµ­ ë“± í•´ì™¸ ì£¼ìš” ì¢…ëª©ê³¼ ì„¹í„° ë¶„ì„\n\n"
                            f"3. **êµ­ë‚´ ì£¼ì‹ ì‹œì¥ ì—°ê´€ì„±**\n"
                            f"   - êµ­ë‚´ ì‹œì¥ì—ì„œë„ ì˜í–¥ì´ ìˆì„ì§€ ì—¬ë¶€ì™€ êµ¬ì²´ì ì¸ ì´ìœ \n"
                            f"   - ì—°ê´€ëœ êµ­ë‚´ ì£¼ì‹ ì¢…ëª©ê³¼ ê´€ë ¨ í…Œë§ˆ\n\n"
                            f"4. **íˆ¬ìì ê´€ì ì˜ ìµœì¢… ê²°ë¡ **\n"
                            f"   - ì‹œì¥ ì‹œê·¸ë„ ìš”ì•½ ë° íˆ¬ì ë§¤ë ¥ë„ ë¶„ì„"
                        )

                        st.text_area("ëª…ë ¹ì–´ ë³µì‚¬ (Ctrl+C)", value=prompt_text, height=150, key=widget_key)
                        st.link_button("ğŸ¤– Gemini ì—´ê¸°", "https://gemini.google.com/app", type="primary", use_container_width=True)

                    st.divider()

        else:
            st.warning(f"í˜„ì¬ '{cat_name}' ì¹´í…Œê³ ë¦¬ì— ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ìë™ í•„í„°ë§ ì¤‘)")
