import streamlit as st
import feedparser
import pandas as pd
from streamlit_autorefresh import st_autorefresh
from datetime import datetime
import urllib.parse  # URL ì¸ì½”ë”©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Stock News Hub", layout="wide")
st.title("ğŸš€ ì¹´í…Œê³ ë¦¬ë³„ ì™¸ì‹  ì‹¤ì‹œê°„ í—ˆë¸Œ")

# 1ë¶„ë§ˆë‹¤ ìë™ ìƒˆë¡œê³ ì¹¨
st_autorefresh(interval=60000, key="newscheck")

# ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES = {
    "AI": "AI OR Artificial Intelligence",
    "ë°˜ë„ì²´": "Semiconductor OR Chips",
    "ì—”ë¹„ë””ì•„": "NVIDIA OR NVDA",
    "í…ŒìŠ¬ë¼": "Tesla OR TSLA",
    "ì¼ë¡  ë¨¸ìŠ¤í¬": '"Elon Musk"'
}

def get_category_news(category_name, query):
    # ì¤‘ìš”: ì¿¼ë¦¬ ë‚´ìš©ì„ URL í˜•ì‹ì— ë§ê²Œ ì¸ì½”ë”© (ê³µë°± -> %20 ë“±)
    encoded_query = urllib.parse.quote(f"{query} when:1h")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    
    feed = feedparser.parse(url)
    news_data = []
    
    if hasattr(feed, 'entries'):
        for entry in feed.entries[:10]:
            news_data.append({
                "ì¹´í…Œê³ ë¦¬": category_name,
                "ì‹œê°„": entry.published,
                "ì œëª©": entry.title,
                "ë§í¬": entry.link,
                "ì¶œì²˜": entry.source.title if hasattr(entry, 'source') else "Google News",
                "dt": pd.to_datetime(entry.published)
            })
    return news_data

# ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ ìˆ˜ì§‘
all_news = []
for cat_name, query in CATEGORIES.items():
    try:
        all_news.extend(get_category_news(cat_name, query))
    except Exception as e:
        st.error(f"{cat_name} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ë°ì´í„° ì¶œë ¥ ë¡œì§
if all_news:
    df = pd.DataFrame(all_news)
    # ì¤‘ë³µ ê¸°ì‚¬ ì œê±° (ì œëª© ê¸°ì¤€)
    df = df.drop_duplicates(subset=['ì œëª©'])
    # ìµœì‹ ìˆœ ì •ë ¬
    df = df.sort_values(by="dt", ascending=False)

    st.subheader(f"ğŸ“ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
    st.divider()

    for _, row in df.iterrows():
        display_text = f"<{row['ì¹´í…Œê³ ë¦¬']}>\n[{row['ì¶œì²˜']}] {row['ì œëª©']}"
        
        with st.container():
            col1, col2 = st.columns([5, 1])
            with col1:
                # ì¹´í…Œê³ ë¦¬ ê°•ì¡° ë””ìì¸
                if row['ì¹´í…Œê³ ë¦¬'] in ["ì—”ë¹„ë””ì•„", "í…ŒìŠ¬ë¼"]:
                    st.success(display_text)
                elif row['ì¹´í…Œê³ ë¦¬'] == "AI":
                    st.info(display_text)
                else:
                    st.write(display_text)
                st.caption(f"ğŸ•’ {row['ì‹œê°„']}")
            with col2:
                st.link_button("ê¸°ì‚¬ ì½ê¸°", row['ë§í¬'])
            st.write("") 
else:
    st.warning("í˜„ì¬ ìƒˆë¡œ ì˜¬ë¼ì˜¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
